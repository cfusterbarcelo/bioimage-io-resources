<config lang="json">
{
    "name": "mws-segmentation",
    "type": "iframe",
    "tags": [],
    "version": "0.1.1",
    "cover": "",
    "description": "Run the mutex watershed for instance segmentation of affinity predictions",
    "icon": "https://raw.githubusercontent.com/ilastik/bioimage-io-models/main/image/mws.png",
    "inputs": null,
    "outputs": null,
    "api_version": "0.1.8",
    "env": "",
    "permissions": [],
    "requirements": ["https://steffenwolf.science/webmutex/mws.js"],
    "dependencies": []
}
</config>

<script lang="javascript">

function readFile(file) {
    return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.readAsArrayBuffer(file);
        reader.onload = () => resolve(reader.result);
        reader.onerror = error => reject(error);
    });
}

class ImJoyPlugin {
    async setup() {
    }
    async run(ctx){
        
        await api.showMessage("Initializing the inference plugin, this may take a while...")
        // https://bioimage.io/#/?tags=affinity&id=10.5281%2Fzenodo.6079314
        ctx.data = ctx.data || {};
        const model_id = ctx.data.id || "10.5281/zenodo.6079314";
        const plugin_source = await api.getAttachment("inference-plugin")
        this.inferencePlugin = await api.loadPlugin({src: plugin_source})
        const self = this;
        const viewer = await api.createWindow({src: "https://kaibu.org/#/app", name: "Kaibu", fullscreen: true})
        await viewer.add_widget({
            "_rintf": true,
            "name": "Control",
            "type": "form",
            "fields": [
                {
                  "type": "files",
                  "label": "Input Image"
                },
                {
                    "html": "<div class='box'><article class='media'><div class='media-content'><div class='content'><p><strong class='has-text-info'>Live Cell Segmentation Boundary Model</strong><br>Try model with your own image or this <a href='https://zenodo.org/api/files/a6d477fe-9412-4064-b7e6-67f057fec920/sample_input_0.tif' target='_blank'>example image</a>. Drag and drop an image in the box above and click 'Submit'.</p></div>"
                },
            ],
            async form_submit_callback(values){
                await viewer.set_loader(true);
                try{
                    const file = values['Input Image'][0]
                    await api.showMessage("Reading input image " + file.name)
                    const bytes = await readFile(file)
                    const input_image = await self.inferencePlugin.render_image(bytes, file.name)
                    await viewer.view_image(input_image, {name: "input image"})
                    await api.showMessage("Running inference...")
                    const result = await self.inferencePlugin.run_inference(model_id, bytes, file.name)
                    console.log('=============', Module)
                    
                    await api.showMessage(result.offsets[0,1])
                    const num_channels = result.nchannels
                    const num_pixels = result.height * result.width

                    var weights = Module.create_float_vector(num_channels * num_pixels);
                    var weight_id = 0;
                    for (var c = 0; c < num_channels; c += 1) {
                        for (var i = 0; i < num_pixels; i += 1) {
                            if (c < 2){
                                weights.set(weight_id, 1 - result.affinities[i + (c * num_pixels)]);
                            }
                            else{
                                weights.set(weight_id, result.affinities[i + (c * num_pixels)]);
                            }
                            weight_id += 1
                        }
                    }

                    var offsets = Module.create_int_vector(num_channels * 2);
                    for (var c = 0; c < num_channels; c += 1) {
                        offsets.set((2*c), result.offsets[c][0]);
                        offsets.set((2*c)+1, result.offsets[c][1]);
                    }

                    await api.showMessage("Computing MWS segmentation")
                    await viewer.view_image(result.vis_sr_aff, {name: "short range affinities"})
                    await viewer.view_image(result.vis_lr_aff, {name: "long range affinities"})

                    var strides = Module.create_int_vector(2);
                    strides.set(0, 4);
                    strides.set(1, 4);

                    const labels = Module.mutex_watershed_2d(weights,
                                               offsets,
                                               strides,
                                               result.height,
                                               result.width,
                                               true);

                    var segmentation = new Int32Array(num_pixels)
                    for (var i = 0; i < num_pixels; i += 1) {
                        segmentation[i] = labels.get(i);
                    }
                    var encoded_label_image = self.inferencePlugin.encode_segmentation(segmentation, result.height, result.width)
                    await viewer.view_image(encoded_label_image, {name: "segmentation"})
                    await api.showMessage("Inference complete")             
                }
                catch(e){
                    await api.alert(`Failed to process the input image, error: ${e}`);
                    console.error(e)
                }
                finally{
                    await viewer.set_loader(false);
                }
            }
        })
    }
}
api.export(new ImJoyPlugin())
</script>

<attachment name="inference-plugin">
<config lang="json">
{
  "name": "mws-inference-plugin",
  "type": "web-python",
  "version": "0.1.0",
  "description": "Affinity model inference",
  "tags": [],
  "ui": "",
  "cover": "",
  "inputs": null,
  "outputs": null,
  "flags": [],
  "icon": "extension",
  "api_version": "0.1.8",
  "env": "",
  "permissions": [],
  "requirements": ["imjoy-rpc", "pillow", "numpy"],
  "dependencies": []
}
</config>

<script lang="python">
from imjoy import api
import io
from PIL import Image
import numpy as np
from imjoy_rpc.hypha import connect_to_server
import base64
import pyodide
from io import BytesIO

def read_image(bytes, name=None, grayscale=False, size=None):
    buffer = io.BytesIO(bytes)
    buffer.name = name or url.split('?')[0].split('/')[1]
    image = Image.open(buffer).convert('L')
    if grayscale:
        image = image.convert('L')
    if size:
        image = image.resize(size=size)
    image = np.array(image)
    return image


def encode_image(image):
    image = Image.fromarray(image)
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = 'data:image/png;base64,' + base64.b64encode(buffered.getvalue()).decode('ascii')
    return img_str


class ImJoyPlugin():
    async def setup(self):
        await api.showMessage("Connecting to the server...")
        server = await connect_to_server(
            {"name": "mws client", "server_url": "https://ai.imjoy.io/", "method_timeout": 3000}
        )
        self.triton = await server.get_service("triton-client")
        await api.showMessage("Connected to the server.")
        await api.log('initialized')

    async def render_image(self, file_bytes, file_name):
        input_image = read_image(file_bytes.tobytes(), name=file_name)
        return encode_image(input_image)

    async def run_inference(self, model_id, file_bytes, file_name):
        input_image = read_image(file_bytes.tobytes(), name=file_name)
        assert input_image.ndim == 2
        # Shape example: (1, 3, 128, 128)
        input_image = input_image[None, None]
        kwargs = {"inputs": [input_image], "model_id": model_id, "return_rdf": True}

        ret = await self.triton.execute(
            inputs=[kwargs],
            model_name="bioengine-model-runner",
            serialization="imjoy",
        )
        result = ret["result"]
        assert result["success"] == True, result["error"]

        offsets = [a for a in [b for b in result['rdf']['config']['mws']['offsets']]]
        visualization_shortrange_affinity = result["outputs"][0][0, 0, :, :] * 255
        visualization_longrange_affinity = result["outputs"][0][0, 4, :, :] * 255
        mask = result["outputs"][0]
        return {"affinities": [float(_) for _ in mask.ravel()],
                "vis_sr_aff": encode_image(visualization_shortrange_affinity.astype('uint8')),
                "vis_lr_aff": encode_image(visualization_longrange_affinity.astype('uint8')),
               "offsets": offsets, "nchannels": len(offsets), "width":mask.shape[-1], "height":mask.shape[-2]}

    def encode_segmentation(self, image, width, height):

        out = np.zeros((width, height,3), dtype=np.uint8)
        n_colors = 1000
        cmap = np.random.randint(40, high=255, size=(n_colors, 3), dtype=np.uint8)

        for i in range(width):
            for j in range(height):
                for c in range(3):
                    out[i, j, c] = cmap[int(image[height*i+j]) % n_colors, c]

        return encode_image(out)

api.export(ImJoyPlugin())
</script>
</attachment>
